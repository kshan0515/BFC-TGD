import os
import datetime
from googleapiclient.discovery import build
from pymongo import MongoClient, UpdateOne

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (GitHub Secrets ë˜ëŠ” Local .env)
YOUTUBE_API_KEY = os.getenv('YOUTUBE_API_KEY')
MONGO_URI = os.getenv('MONGO_URI')
DB_NAME = 'bfc-tgd'

def scrape_youtube():
    keywords = ['ë¶€ì²œFC', 'ë¶€ì²œFC1995', 'BFC1995']
    if not YOUTUBE_API_KEY or not MONGO_URI:
        print("âŒ Error: YOUTUBE_API_KEY or MONGO_URI environment variable is not set.")
        return

    # 1ì£¼ì¼ ì „ ì‹œê°„ ê³„ì‚°
    time_threshold = (datetime.datetime.utcnow() - datetime.timedelta(days=7)).isoformat() + "Z"
    print(f"ğŸš€ Starting YouTube scrape for keywords: {', '.join(keywords)}")
    print(f"ğŸ“… Fetching videos published after: {time_threshold} (Last 7 days)")

    try:
        # 1. ìœ íŠœë¸Œ API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)
        
        all_collected_items = []
        
        for keyword in keywords:
            print(f"ğŸ” Searching for: {keyword}...")
            collected_for_keyword = []
            next_page_token = None
            max_per_keyword = 50 # ê° í‚¤ì›Œë“œë³„ ìµœëŒ€ 50ê°œ
            
            while len(collected_for_keyword) < max_per_keyword:
                request = youtube.search().list(
                    part="snippet",
                    q=keyword,
                    maxResults=50,
                    type="video",
                    order="date",
                    publishedAfter=time_threshold,
                    pageToken=next_page_token
                )
                response = request.execute()
                
                items = response.get('items', [])
                if not items:
                    break
                    
                collected_for_keyword.extend(items)
                next_page_token = response.get('nextPageToken')
                
                if not next_page_token:
                    break
            
            all_collected_items.extend(collected_for_keyword)
            print(f"âœ… Found {len(collected_for_keyword)} items for '{keyword}'")

        # 2. MongoDB Atlas ì—°ê²°
        client = MongoClient(MONGO_URI)
        db = client[DB_NAME]
        collection = db['contents']

        operations = []
        for item in all_collected_items:
            video_id = item['id']['videoId']
            snippet = item['snippet']
            
            content_doc = {
                "external_id": video_id,
                "platform": "YOUTUBE",
                "type": "VIDEO",
                "title": snippet['title'],
                "caption": snippet['description'],
                "media_uri": snippet['thumbnails']['high']['url'],
                "origin_url": f"https://www.youtube.com/watch?v={video_id}",
                "published_at": snippet['publishedAt'],
                "username": snippet['channelTitle'],
                "metadata": {
                    "channel_id": snippet['channelId'],
                    "videoId": video_id
                },
                "updated_at": datetime.datetime.utcnow()
            }

            operations.append(
                UpdateOne(
                    {"external_id": video_id},
                    {"$set": content_doc},
                    upsert=True
                )
            )

        # 3. ë²Œí¬ ì‹¤í–‰
        if operations:
            result = collection.bulk_write(operations)
            print(f"âœ… [v2.3] Final Success! Total {len(all_collected_items)} records processed.")
            print(f"ğŸ“Š Stats - Upserted: {result.upserted_count}, Matched: {result.matched_count}")
        else:
            print("âš ï¸ No videos found for any keywords in the last week.")

    except Exception as e:
        print(f"âŒ Critical Error: {str(e)}")

if __name__ == "__main__":
    scrape_youtube()
